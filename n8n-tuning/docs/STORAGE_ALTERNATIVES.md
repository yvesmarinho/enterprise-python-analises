# ğŸ“Š Alternativas para Armazenamento de MÃ©tricas do N8N

**Ãšltima AtualizaÃ§Ã£o**: 03/02/2026  
**Objetivo**: Armazenar dados de performance do N8N para anÃ¡lise temporal

---

## ğŸ¯ Alternativas DisponÃ­veis

### 1. ğŸ˜ PostgreSQL (RECOMENDADO) â­â­â­

**Vantagens:**
- âœ… VocÃª jÃ¡ tem acesso ao servidor (wfdb02.vya.digital)
- âœ… UsuÃ¡rio read-only existente (n8n_tuning_read)
- âœ… Pode criar schema separado para mÃ©tricas
- âœ… Excelente para anÃ¡lises com SQL
- âœ… Suporta TimescaleDB (extensÃ£o time-series)
- âœ… FÃ¡cil integraÃ§Ã£o com ferramentas de BI

**Estrutura Proposta:**
```sql
-- Schema para mÃ©tricas
CREATE SCHEMA IF NOT EXISTS n8n_metrics;

-- Tabela de snapshots de workflows
CREATE TABLE n8n_metrics.workflow_snapshots (
    id SERIAL PRIMARY KEY,
    collected_at TIMESTAMP DEFAULT NOW(),
    workflow_id VARCHAR(50),
    workflow_name VARCHAR(255),
    active BOOLEAN,
    nodes_count INTEGER,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    raw_data JSONB
);

-- Tabela de execuÃ§Ãµes
CREATE TABLE n8n_metrics.execution_metrics (
    id SERIAL PRIMARY KEY,
    collected_at TIMESTAMP DEFAULT NOW(),
    execution_id VARCHAR(50) UNIQUE,
    workflow_id VARCHAR(50),
    workflow_name VARCHAR(255),
    started_at TIMESTAMP,
    stopped_at TIMESTAMP,
    duration_ms INTEGER,
    finished BOOLEAN,
    success BOOLEAN,
    mode VARCHAR(50),
    raw_data JSONB
);

-- Ãndices para queries rÃ¡pidas
CREATE INDEX idx_execution_workflow ON n8n_metrics.execution_metrics(workflow_id);
CREATE INDEX idx_execution_started ON n8n_metrics.execution_metrics(started_at);
CREATE INDEX idx_workflow_collected ON n8n_metrics.workflow_snapshots(collected_at);
```

**Uso:**
- Coletar dados via API a cada X minutos/horas
- Inserir no PostgreSQL
- Queries SQL para anÃ¡lise
- Grafana conectado ao PostgreSQL para visualizaÃ§Ã£o

---

### 2. ğŸ“¦ SQLite Local â­â­â­

**Vantagens:**
- âœ… NÃ£o precisa de servidor
- âœ… Arquivo Ãºnico e portÃ¡vel
- âœ… Suporte completo a SQL
- âœ… FÃ¡cil backup e compartilhamento
- âœ… Bibliotecas Python nativas

**Estrutura:**
```
n8n-tuning/
â””â”€â”€ data/
    â””â”€â”€ metrics_db/
        â””â”€â”€ n8n_metrics.db  (SQLite)
```

**Uso:**
```python
import sqlite3
from datetime import datetime

# Conectar ao banco
conn = sqlite3.connect('data/metrics_db/n8n_metrics.db')

# Inserir mÃ©tricas
cursor.execute("""
    INSERT INTO execution_metrics 
    (execution_id, workflow_id, duration_ms, success, collected_at)
    VALUES (?, ?, ?, ?, ?)
""", (exec_id, wf_id, duration, success, datetime.now()))
```

---

### 3. ğŸ“ˆ InfluxDB (Time-Series DB) â­â­

**Vantagens:**
- âœ… Especializado em time-series
- âœ… Queries otimizadas para mÃ©tricas
- âœ… RetenÃ§Ã£o automÃ¡tica de dados
- âœ… IntegraÃ§Ã£o com Grafana

**Desvantagens:**
- âŒ Requer instalaÃ§Ã£o de servidor
- âŒ Mais complexo que SQLite/PostgreSQL

**Quando usar:**
- Se vocÃª pretende coletar mÃ©tricas em alta frequÃªncia (< 1 min)
- Se precisa de dashboards em tempo real
- Se vai coletar milhÃµes de data points

---

### 4. ğŸ“Š Parquet Files (AnÃ¡lise de Dados) â­â­

**Vantagens:**
- âœ… Formato colunar eficiente
- âœ… CompressÃ£o excelente
- âœ… IntegraÃ§Ã£o com pandas/polars
- âœ… CompatÃ­vel com Spark, DuckDB

**Uso:**
```python
import pandas as pd

# Salvar mÃ©tricas
df = pd.DataFrame(metrics)
df.to_parquet('data/metrics_db/executions_2026-02.parquet')

# Ler e analisar
df = pd.read_parquet('data/metrics_db/executions_2026-02.parquet')
df.groupby('workflow_id')['duration_ms'].mean()
```

---

### 5. ğŸ”¥ Hybrid: JSON + DuckDB â­â­â­

**Vantagens:**
- âœ… Melhor dos dois mundos
- âœ… JSON para coleta (jÃ¡ estamos fazendo)
- âœ… DuckDB para anÃ¡lise SQL rÃ¡pida
- âœ… NÃ£o precisa importar dados

**Uso:**
```python
import duckdb

# Query diretamente nos JSONs
conn = duckdb.connect()
result = conn.execute("""
    SELECT 
        workflowId,
        COUNT(*) as executions,
        AVG(duration) as avg_duration
    FROM read_json_auto('data/metrics/executions_*.json')
    GROUP BY workflowId
    ORDER BY avg_duration DESC
""").fetchdf()
```

---

## ğŸš€ Usando Partes da Stack Prometheus

### OpÃ§Ã£o A: Formato Prometheus (sem servidor)

**Usar bibliotecas Python:**
```python
from prometheus_client import CollectorRegistry, Gauge, write_to_textfile

registry = CollectorRegistry()

# Definir mÃ©tricas
workflow_duration = Gauge(
    'n8n_workflow_duration_seconds',
    'DuraÃ§Ã£o do workflow',
    ['workflow_id', 'workflow_name'],
    registry=registry
)

# Registrar mÃ©tricas
workflow_duration.labels(
    workflow_id='abc123',
    workflow_name='my-workflow'
).set(45.5)

# Salvar em arquivo
write_to_textfile('data/metrics/n8n_metrics.prom', registry)
```

**Vantagens:**
- Formato padrÃ£o da indÃºstria
- Pode ser importado depois no Prometheus
- Node Exporter pode ler os arquivos

---

### OpÃ§Ã£o B: Prometheus + Node Exporter (Textfile Collector)

**Se vocÃª tiver Node Exporter rodando:**
```bash
# Gerar mÃ©tricas em formato Prometheus
python scripts/generate_prometheus_metrics.py > /var/lib/node_exporter/n8n.prom

# Node Exporter expÃµe automaticamente
curl http://localhost:9100/metrics | grep n8n_
```

---

## ğŸ“‹ RecomendaÃ§Ã£o Final

### Para o seu caso (N8N Tuning):

**ğŸ¥‡ OpÃ§Ã£o 1: PostgreSQL + DuckDB**
```
Coleta â†’ API N8N â†’ Save JSON â†’ PostgreSQL (histÃ³rico)
                              â†˜ DuckDB (anÃ¡lise rÃ¡pida)
```

**Por quÃª:**
1. PostgreSQL - VocÃª jÃ¡ tem acesso, pode criar schema `n8n_metrics`
2. DuckDB - Query rÃ¡pida nos JSONs sem importar
3. Grafana - Pode conectar no PostgreSQL para dashboards

**ğŸ¥ˆ OpÃ§Ã£o 2: SQLite + JSON**
```
Coleta â†’ API N8N â†’ Save JSON (raw)
                  â†’ SQLite (estruturado)
```

**Por quÃª:**
1. Simples e portÃ¡til
2. NÃ£o precisa de servidor adicional
3. FÃ¡cil anÃ¡lise com Python/pandas

---

## ğŸ› ï¸ ImplementaÃ§Ã£o Sugerida

**Fase 1: Coleta BÃ¡sica (Agora)**
- âœ… Salvar JSONs timestamped (jÃ¡ estÃ¡ fazendo)
- âœ… DuckDB para queries ad-hoc

**Fase 2: Armazenamento Estruturado (Semana 1)**
- PostgreSQL schema `n8n_metrics`
- Script de ingestÃ£o automÃ¡tica
- RetenÃ§Ã£o de 90 dias

**Fase 3: VisualizaÃ§Ã£o (Semana 2)**
- Grafana + PostgreSQL
- Dashboards de performance
- Alertas de anomalias

---

## ğŸ’¡ Quer que eu implemente qual opÃ§Ã£o?

1. **PostgreSQL schema + ingestor** (recomendado para produÃ§Ã£o)
2. **SQLite local** (recomendado para testes rÃ¡pidos)
3. **DuckDB queries** (recomendado para anÃ¡lise imediata)
4. **Hybrid (JSON + PostgreSQL + DuckDB)** (melhor dos mundos)

Escolha uma e eu implemento agora! ğŸš€
