#!/usr/bin/env python3
"""
N8N Metrics Exporter para Victoria Metrics
Coleta m√©tricas do N8N via API e exporta para Victoria Metrics em formato Prometheus
"""

import requests
import json
import time
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from collections import defaultdict

# Adicionar o diret√≥rio scripts ao path
sys.path.insert(0, str(Path(__file__).parent))

from credentials_helper import CredentialsManager


class N8NMetricsExporter:
    """Exportador de m√©tricas do N8N para Victoria Metrics ou Prometheus"""
    
    def __init__(self, n8n_url: str, n8n_api_key: str, 
                 vm_url: str = "http://localhost:8428",
                 prometheus_pushgateway: str = None,
                 prometheus_job: str = "n8n_metrics",
                 backend: str = "victoria_metrics"):
        """
        Inicializa o exportador
        
        Args:
            n8n_url: URL do N8N
            n8n_api_key: API Key do N8N
            vm_url: URL do Victoria Metrics
            prometheus_pushgateway: URL do Prometheus Pushgateway (ex: http://wfdb01.vya.digital:9091)
            prometheus_job: Nome do job no Prometheus
            backend: 'victoria_metrics' ou 'prometheus'
        """
        self.n8n_url = n8n_url.rstrip('/')
        self.n8n_api_key = n8n_api_key
        self.vm_url = vm_url.rstrip('/')
        self.prometheus_pushgateway = prometheus_pushgateway.rstrip('/') if prometheus_pushgateway else None
        self.prometheus_job = prometheus_job
        self.backend = backend
        
        self.headers = {
            "X-N8N-API-KEY": n8n_api_key,
            "Accept": "application/json"
        }
    
    def _make_n8n_request(self, endpoint: str, params: Optional[Dict] = None) -> Dict:
        """Faz requisi√ß√£o √† API do N8N"""
        url = f"{self.n8n_url}{endpoint}"
        
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erro ao fazer requisi√ß√£o para {endpoint}: {e}")
            return {}
    
    def collect_workflows(self) -> List[Dict]:
        """Coleta informa√ß√µes de workflows"""
        print("üìä Coletando workflows...")
        data = self._make_n8n_request("/api/v1/workflows")
        workflows = data.get('data', [])
        print(f"‚úÖ {len(workflows)} workflows coletados")
        return workflows
    
    def collect_executions(self, total_limit: int = 1000) -> List[Dict]:
        """
        Coleta execu√ß√µes recentes com pagina√ß√£o
        
        Args:
            total_limit: N√∫mero m√°ximo total de execu√ß√µes a coletar
            
        Returns:
            Lista de execu√ß√µes (API limita 250 por requisi√ß√£o)
        """
        print(f"üìä Coletando execu√ß√µes (at√© {total_limit} registros)...")
        
        all_executions = []
        cursor = None
        max_per_page = 250  # Limite da API N8N
        
        while len(all_executions) < total_limit:
            # Calcular quantos registros pegar nesta p√°gina
            remaining = total_limit - len(all_executions)
            page_limit = min(remaining, max_per_page)
            
            # Montar par√¢metros
            params = {"limit": page_limit}
            if cursor:
                params["cursor"] = cursor
            
            # Fazer requisi√ß√£o
            data = self._make_n8n_request("/api/v1/executions", params=params)
            page_executions = data.get('data', [])
            
            if not page_executions:
                break  # Sem mais dados
            
            all_executions.extend(page_executions)
            print(f"   üìÑ P√°gina coletada: {len(page_executions)} registros (total: {len(all_executions)})")
            
            # Verificar se h√° pr√≥xima p√°gina
            cursor = data.get('nextCursor')
            if not cursor:
                break  # N√£o h√° mais p√°ginas
        
        print(f"‚úÖ {len(all_executions)} execu√ß√µes coletadas")
        return all_executions
    
    def generate_prometheus_metrics(self, workflows: List[Dict], executions: List[Dict]) -> str:
        """
        Gera m√©tricas em formato Prometheus
        
        Returns:
            String com m√©tricas em formato Prometheus
        """
        lines = []
        timestamp = int(time.time() * 1000)  # Timestamp em milissegundos
        
        # M√©tricas de Workflows
        lines.append("# HELP n8n_workflows_total Total number of workflows")
        lines.append("# TYPE n8n_workflows_total gauge")
        lines.append(f"n8n_workflows_total {len(workflows)} {timestamp}")
        
        active_workflows = sum(1 for wf in workflows if wf.get('active', False))
        lines.append("# HELP n8n_workflows_active Number of active workflows")
        lines.append("# TYPE n8n_workflows_active gauge")
        lines.append(f"n8n_workflows_active {active_workflows} {timestamp}")
        
        # M√©tricas por workflow individual
        lines.append("# HELP n8n_workflow_info Workflow information")
        lines.append("# TYPE n8n_workflow_info gauge")
        
        for wf in workflows:
            wf_id = wf.get('id', 'unknown')
            wf_name = wf.get('name', 'unknown').replace('"', '\\"')
            active = 1 if wf.get('active', False) else 0
            nodes_count = len(wf.get('nodes', []))
            
            lines.append(
                f'n8n_workflow_info{{workflow_id="{wf_id}",workflow_name="{wf_name}",active="{active}"}} '
                f'{nodes_count} {timestamp}'
            )
        
        # M√©tricas de Execu√ß√µes
        lines.append("# HELP n8n_executions_total Total number of executions")
        lines.append("# TYPE n8n_executions_total gauge")
        lines.append(f"n8n_executions_total {len(executions)} {timestamp}")
        
        # Criar mapa de workflow IDs para nomes
        workflow_names = {wf.get('id'): wf.get('name', 'unknown') for wf in workflows}
        
        # Filtrar apenas execu√ß√µes de workflows que ainda existem
        valid_executions = [
            exec for exec in executions 
            if exec.get('workflowId') in workflow_names
        ]
        
        # Log de execu√ß√µes filtradas
        filtered_count = len(executions) - len(valid_executions)
        if filtered_count > 0:
            print(f"   ‚ö†Ô∏è  {filtered_count} execu√ß√µes de workflows deletados foram filtradas")
        
        # Agregar execu√ß√µes por workflow
        workflow_executions = defaultdict(lambda: {'total': 0, 'success': 0, 'failed': 0, 'duration': [], 'name': 'unknown'})
        
        for exec in valid_executions:
            wf_id = exec.get('workflowId')
            finished = exec.get('finished', False)
            stopped_at = exec.get('stoppedAt')
            started_at = exec.get('startedAt')
            
            # Usar o nome do workflow do mapa criado
            workflow_executions[wf_id]['name'] = workflow_names[wf_id]
            
            workflow_executions[wf_id]['total'] += 1
            
            # Determinar sucesso/falha
            if finished:
                if stopped_at and not exec.get('data', {}).get('resultData', {}).get('error'):
                    workflow_executions[wf_id]['success'] += 1
                else:
                    workflow_executions[wf_id]['failed'] += 1
            
            # Calcular dura√ß√£o
            if started_at and stopped_at:
                try:
                    start = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                    stop = datetime.fromisoformat(stopped_at.replace('Z', '+00:00'))
                    duration = (stop - start).total_seconds()
                    workflow_executions[wf_id]['duration'].append(duration)
                except:
                    pass
        
        # M√©tricas por workflow
        lines.append("# HELP n8n_workflow_executions_total Total executions per workflow")
        lines.append("# TYPE n8n_workflow_executions_total gauge")
        
        for wf_id, data in workflow_executions.items():
            wf_name = data['name'].replace('"', '\\"')
            lines.append(
                f'n8n_workflow_executions_total{{workflow_id="{wf_id}",workflow_name="{wf_name}"}} '
                f'{data["total"]} {timestamp}'
            )
        
        lines.append("# HELP n8n_workflow_executions_success Successful executions per workflow")
        lines.append("# TYPE n8n_workflow_executions_success gauge")
        
        for wf_id, data in workflow_executions.items():
            wf_name = data['name'].replace('"', '\\"')
            lines.append(
                f'n8n_workflow_executions_success{{workflow_id="{wf_id}",workflow_name="{wf_name}"}} '
                f'{data["success"]} {timestamp}'
            )
        
        lines.append("# HELP n8n_workflow_executions_failed Failed executions per workflow")
        lines.append("# TYPE n8n_workflow_executions_failed gauge")
        
        for wf_id, data in workflow_executions.items():
            wf_name = data['name'].replace('"', '\\"')
            lines.append(
                f'n8n_workflow_executions_failed{{workflow_id="{wf_id}",workflow_name="{wf_name}"}} '
                f'{data["failed"]} {timestamp}'
            )
        
        # Dura√ß√£o m√©dia por workflow
        lines.append("# HELP n8n_workflow_execution_duration_seconds Average execution duration per workflow")
        lines.append("# TYPE n8n_workflow_execution_duration_seconds gauge")
        
        for wf_id, data in workflow_executions.items():
            if data['duration']:
                avg_duration = sum(data['duration']) / len(data['duration'])
                wf_name = data['name'].replace('"', '\\"')
                lines.append(
                    f'n8n_workflow_execution_duration_seconds{{workflow_id="{wf_id}",workflow_name="{wf_name}"}} '
                    f'{avg_duration:.2f} {timestamp}'
                )
        
        # Taxa de sucesso global
        total_finished = sum(d['success'] + d['failed'] for d in workflow_executions.values())
        total_success = sum(d['success'] for d in workflow_executions.values())
        
        if total_finished > 0:
            success_rate = (total_success / total_finished) * 100
            lines.append("# HELP n8n_success_rate_percent Overall success rate percentage")
            lines.append("# TYPE n8n_success_rate_percent gauge")
            lines.append(f"n8n_success_rate_percent {success_rate:.2f} {timestamp}")
        
        return '\n'.join(lines) + '\n'
    
    def push_to_victoria_metrics(self, metrics: str) -> bool:
        """
        Envia m√©tricas para Victoria Metrics
        
        Args:
            metrics: String com m√©tricas em formato Prometheus
            
        Returns:
            True se sucesso, False caso contr√°rio
        """
        url = f"{self.vm_url}/api/v1/import/prometheus"
        
        try:
            response = requests.post(url, data=metrics, timeout=10)
            response.raise_for_status()
            print("‚úÖ M√©tricas enviadas para Victoria Metrics com sucesso")
            return True
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erro ao enviar m√©tricas para Victoria Metrics: {e}")
            return False
    
    def push_to_prometheus_pushgateway(self, metrics: str) -> bool:
        """
        Envia m√©tricas para Prometheus Pushgateway
        
        Args:
            metrics: String com m√©tricas em formato Prometheus
            
        Returns:
            True se sucesso, False caso contr√°rio
        """
        if not self.prometheus_pushgateway:
            print("‚ùå URL do Prometheus Pushgateway n√£o configurado")
            return False
        
        url = f"{self.prometheus_pushgateway}/metrics/job/{self.prometheus_job}"
        
        try:
            response = requests.post(url, data=metrics, timeout=10)
            response.raise_for_status()
            print(f"‚úÖ M√©tricas enviadas para Prometheus Pushgateway com sucesso")
            print(f"   Job: {self.prometheus_job}")
            print(f"   URL: {self.prometheus_pushgateway}")
            return True
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erro ao enviar m√©tricas para Prometheus: {e}")
            print(f"   Verifique se o Pushgateway est√° rodando em: {self.prometheus_pushgateway}")
            return False
    
    def push_metrics(self, metrics: str) -> bool:
        """
        Envia m√©tricas para o backend configurado
        
        Args:
            metrics: String com m√©tricas em formato Prometheus
            
        Returns:
            True se sucesso, False caso contr√°rio
        """
        if self.backend == "prometheus":
            return self.push_to_prometheus_pushgateway(metrics)
        else:
            return self.push_to_victoria_metrics(metrics)
    
    def collect_and_push(self, executions_limit: int = 100) -> bool:
        """
        Coleta m√©tricas do N8N e envia para Victoria Metrics
        
        Args:
            executions_limit: N√∫mero de execu√ß√µes para analisar
            
        Returns:
            True se sucesso, False caso contr√°rio
        """
        print("=" * 60)
        print("üöÄ N8N Metrics Exporter")
        print("=" * 60)
        print()
        
        # Coletar dados
        workflows = self.collect_workflows()
        executions = self.collect_executions(total_limit=executions_limit)
        
        if not workflows and not executions:
            print("‚ö†Ô∏è  Nenhum dado coletado")
            return False
        
        print()
        print("üìà Gerando m√©tricas Prometheus...")
        metrics = self.generate_prometheus_metrics(workflows, executions)
        
        # Mostrar preview
        lines = metrics.split('\n')
        metric_lines = [l for l in lines if l and not l.startswith('#')]
        print(f"‚úÖ {len(metric_lines)} m√©tricas geradas")
        
        print()
        print("üì§ Enviando para Victoria Metrics...")
        success = self.push_metrics(metrics)
        
        print()
        print("=" * 60)
        if success:
            print("‚úÖ Coleta e exporta√ß√£o conclu√≠das com sucesso!")
            print()
            print("üîç Verificar m√©tricas:")
            if self.backend == "prometheus":
                print(f"   Prometheus Pushgateway: {self.prometheus_pushgateway}")
                print(f"   Job name: {self.prometheus_job}")
            else:
                print(f"   Victoria Metrics: {self.vm_url}")
                print(f"   Grafana: http://localhost:3100")
        else:
            print("‚ùå Falha na exporta√ß√£o")
        print("=" * 60)
        
        return success


def main():
    """Fun√ß√£o principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description='N8N Metrics Exporter')
    parser.add_argument('--backend', choices=['victoria_metrics', 'prometheus'], 
                        default='prometheus',
                        help='Backend para enviar m√©tricas (default: prometheus)')
    parser.add_argument('--limit', type=int, default=1000,
                        help='N√∫mero de execu√ß√µes a coletar (default: 1000)')
    args = parser.parse_args()
    
    print("üîç Carregando credenciais...")
    
    try:
        creds = CredentialsManager()
        n8n_config = creds.get_n8n_config()
        
        n8n_url = n8n_config.get('url')
        api_key = n8n_config.get('api_key')
        
        if not n8n_url or not api_key:
            print("‚ùå URL ou API Key do N8N n√£o encontrados")
            sys.exit(1)
        
        print(f"‚úÖ N8N URL: {n8n_url}")
        print(f"‚úÖ Backend: {args.backend}")
        print()
        
        # Configurar backend
        if args.backend == "prometheus":
            prom_config = creds.get_prometheus_config()
            pushgateway_url = prom_config.get('pushgateway_url', 'http://wfdb01.vya.digital:9091')
            job_name = prom_config.get('job_name', 'n8n_metrics')
            
            print(f"‚úÖ Prometheus Pushgateway: {pushgateway_url}")
            print(f"‚úÖ Job name: {job_name}")
            print()
            
            exporter = N8NMetricsExporter(
                n8n_url=n8n_url,
                n8n_api_key=api_key,
                prometheus_pushgateway=pushgateway_url,
                prometheus_job=job_name,
                backend="prometheus"
            )
        else:
            # Victoria Metrics
            exporter = N8NMetricsExporter(
                n8n_url=n8n_url,
                n8n_api_key=api_key,
                vm_url="http://localhost:8428",
                backend="victoria_metrics"
            )
        
        # Coletar e exportar
        success = exporter.collect_and_push(executions_limit=args.limit)
        
        sys.exit(0 if success else 1)
        
    except FileNotFoundError as e:
        print(f"‚ùå {e}")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
